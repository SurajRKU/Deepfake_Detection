{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, jsonify, request\n",
    "\n",
    "app = Flask(__name__)\n",
    "       \n",
    "# %%\n",
    "import shutil\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "import sys, os.path\n",
    "import json\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from efficientnet.keras import EfficientNetB0\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "print(tf.__version__)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2,suppress=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename_only(file_path):\n",
    "    file_basename = os.path.basename(file_path)\n",
    "    filename_only = file_basename.split('.')[0]\n",
    "    return filename_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vid_to_img(base_path,filename):\n",
    "    print(filename)\n",
    "    if (filename.endswith(\".mp4\")):\n",
    "        tmp_path = os.path.join(base_path, get_filename_only(filename))\n",
    "        print('Creating Directory: ' + tmp_path)\n",
    "        os.makedirs(tmp_path, exist_ok=True)\n",
    "        print('Converting Video to Images...')\n",
    "        count = 0\n",
    "        video_file = os.path.join(base_path, filename)\n",
    "        cap = cv2.VideoCapture(video_file)\n",
    "        frame_rate = cap.get(5) #frame rate\n",
    "        while(cap.isOpened()):\n",
    "            frame_id = cap.get(1) #current frame number\n",
    "            ret, frame = cap.read()\n",
    "            if (ret != True):\n",
    "                break\n",
    "            if (frame_id % math.floor(frame_rate) == 0):\n",
    "                print('Original Dimensions: ', frame.shape)\n",
    "                if frame.shape[1] < 300:\n",
    "                    scale_ratio = 2\n",
    "                elif frame.shape[1] > 1900:\n",
    "                    scale_ratio = 0.33\n",
    "                elif frame.shape[1] > 1000 and frame.shape[1] <= 1900 :\n",
    "                    scale_ratio = 0.5\n",
    "                else:\n",
    "                    scale_ratio = 1\n",
    "                print('Scale Ratio: ', scale_ratio)\n",
    "\n",
    "                width = int(frame.shape[1] * scale_ratio)\n",
    "                height = int(frame.shape[0] * scale_ratio)\n",
    "                dim = (width, height)\n",
    "                new_frame = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
    "                print('Resized Dimensions: ', new_frame.shape)\n",
    "\n",
    "                new_filename = '{}-{:03d}.png'.format(os.path.join(tmp_path, get_filename_only(filename)), count)\n",
    "                count = count + 1\n",
    "                cv2.imwrite(new_filename, new_frame)\n",
    "                #if(count == 2):\n",
    "                #    break\n",
    "        cap.release()\n",
    "        print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_faces(base_path,filename):\n",
    "    tmp_path = os.path.join(base_path, get_filename_only(filename))\n",
    "    print('Processing Directory: ' + tmp_path)\n",
    "    frame_images = [x for x in os.listdir(tmp_path) if os.path.isfile(os.path.join(tmp_path, x))]\n",
    "    faces_path = os.path.join(tmp_path, 'faces')\n",
    "    print('Creating Directory: ' + faces_path)\n",
    "    os.makedirs(faces_path, exist_ok=True)\n",
    "    print('Cropping Faces from Images...')\n",
    "\n",
    "    for frame in frame_images:\n",
    "        print('Processing ', frame)\n",
    "        detector = MTCNN()\n",
    "        image = cv2.cvtColor(cv2.imread(os.path.join(tmp_path, frame)), cv2.COLOR_BGR2RGB)\n",
    "        results = detector.detect_faces(image)\n",
    "        print('Face Detected: ', len(results))\n",
    "        count = 0\n",
    "        for result in results:\n",
    "            bounding_box = result['box']\n",
    "            print(bounding_box)\n",
    "            confidence = result['confidence']\n",
    "            print(confidence)\n",
    "            if len(results) < 2 or confidence > 0.95:\n",
    "                margin_x = bounding_box[2] * 0.3  # 30% as the margin\n",
    "                margin_y = bounding_box[3] * 0.3  # 30% as the margin\n",
    "                x1 = int(bounding_box[0] - margin_x)\n",
    "                if x1 < 0:\n",
    "                    x1 = 0\n",
    "                x2 = int(bounding_box[0] + bounding_box[2] + margin_x)\n",
    "                if x2 > image.shape[1]:\n",
    "                    x2 = image.shape[1]\n",
    "                y1 = int(bounding_box[1] - margin_y)\n",
    "                if y1 < 0:\n",
    "                    y1 = 0\n",
    "                y2 = int(bounding_box[1] + bounding_box[3] + margin_y)\n",
    "                if y2 > image.shape[0]:\n",
    "                    y2 = image.shape[0]\n",
    "                print(x1, y1, x2, y2)\n",
    "                crop_image = image[y1:y2, x1:x2]\n",
    "                new_filename = '{}-{:02d}.png'.format(os.path.join(faces_path, get_filename_only(frame)), count)\n",
    "                count = count + 1\n",
    "                cv2.imwrite(new_filename, cv2.cvtColor(crop_image, cv2.COLOR_RGB2BGR))\n",
    "            else:\n",
    "                print('Skipped a face..')\n",
    "    #faces_number=os.listdir(faces_path)\n",
    "    #if(faces_number < 3):\n",
    "    #    print(\"The Video Provided has poor lighting or has no faces\")\n",
    "    return faces_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(faces_path,faces):\n",
    "    model = load_model('./best_model_DFDC40_res.h5')\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['val_accuracy'])\n",
    "    count=0\n",
    "    classes=np.empty([1])\n",
    "    for face in faces:\n",
    "        img = tf.keras.preprocessing.image.load_img(os.path.join(faces_path,face), target_size=(128, 128))\n",
    "        img_tensor = tf.keras.preprocessing.image.img_to_array(img)                    # (height, width, channels)\n",
    "        img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
    "        img_tensor /= 255.  \n",
    "\n",
    "        classes =model.predict(img_tensor)\n",
    "        if(classes[0][0]>0.75):\n",
    "            count+=1\n",
    "        if count>=2:\n",
    "            return classes\n",
    "            \n",
    "        print(classes)\n",
    "       \n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute():\n",
    "        np.set_printoptions(precision=8,suppress=True)\n",
    "        basepath=\"C:/Users/\"+ \"Fahad/Downloads/video_selected.mp4\"\n",
    "        basedir=os.path.dirname(basepath)\n",
    "        print(basedir)\n",
    "        filename=os.path.basename(basepath)\n",
    "        print(filename)\n",
    "        vid_to_img(basedir,filename)\n",
    "        faces_path = crop_faces(basedir,filename)\n",
    "        faces=os.listdir(faces_path)\n",
    "        print(faces)\n",
    "        prediction=predict(faces_path,faces)\n",
    "        basepath_upd=\"C:/Users/Fahad/Downloads/video_selected\"\n",
    "        shutil.rmtree(basepath_upd)\n",
    "        os.remove(basepath)\n",
    "        return prediction\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [21/Jun/2021 22:20:01] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [21/Jun/2021 22:20:01] \"\u001b[36mGET /static/js/index.js HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [21/Jun/2021 22:20:01] \"\u001b[37mGET /static/css/style.css HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [21/Jun/2021 22:20:01] \"\u001b[36mGET /static/file.svg HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [21/Jun/2021 22:20:01] \"\u001b[36mGET /static/css/bg-upload.svg HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [21/Jun/2021 22:20:13] \"\u001b[37mGET /loading HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [21/Jun/2021 22:20:13] \"\u001b[37mGET /static/css/style.css HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Fahad/Downloads\n",
      "video_selected.mp4\n",
      "video_selected.mp4\n",
      "Creating Directory: C:/Users/Fahad/Downloads\\video_selected\n",
      "Converting Video to Images...\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Done!\n",
      "Processing Directory: C:/Users/Fahad/Downloads\\video_selected\n",
      "Creating Directory: C:/Users/Fahad/Downloads\\video_selected\\faces\n",
      "Cropping Faces from Images...\n",
      "Processing  video_selected-000.png\n",
      "Face Detected:  0\n",
      "Processing  video_selected-001.png\n",
      "Face Detected:  2\n",
      "[241, 72, 27, 36]\n",
      "0.9993242025375366\n",
      "232 61 276 118\n",
      "[378, 56, 30, 43]\n",
      "0.7455229759216309\n",
      "Skipped a face..\n",
      "Processing  video_selected-002.png\n",
      "Face Detected:  2\n",
      "[402, 62, 23, 33]\n",
      "0.9999290704727173\n",
      "395 52 431 104\n",
      "[244, 73, 25, 34]\n",
      "0.9998849630355835\n",
      "236 62 276 117\n",
      "Processing  video_selected-003.png\n",
      "Face Detected:  2\n",
      "[378, 63, 24, 33]\n",
      "0.9999996423721313\n",
      "370 53 409 105\n",
      "[243, 70, 26, 38]\n",
      "0.999887228012085\n",
      "235 58 276 119\n",
      "Processing  video_selected-004.png\n",
      "Face Detected:  2\n",
      "[384, 62, 24, 34]\n",
      "0.9999954700469971\n",
      "376 51 415 106\n",
      "[251, 71, 23, 36]\n",
      "0.9999442100524902\n",
      "244 60 280 117\n",
      "Processing  video_selected-005.png\n",
      "Face Detected:  2\n",
      "[371, 60, 25, 36]\n",
      "0.999985933303833\n",
      "363 49 403 106\n",
      "[245, 71, 25, 35]\n",
      "0.9996850490570068\n",
      "237 60 277 116\n",
      "Processing  video_selected-006.png\n",
      "Face Detected:  2\n",
      "[368, 62, 26, 36]\n",
      "0.9999996423721313\n",
      "360 51 401 108\n",
      "[243, 71, 27, 36]\n",
      "0.9995806813240051\n",
      "234 60 278 117\n",
      "Processing  video_selected-007.png\n",
      "Face Detected:  2\n",
      "[365, 65, 24, 32]\n",
      "0.9999843835830688\n",
      "357 55 396 106\n",
      "[247, 75, 24, 35]\n",
      "0.999874472618103\n",
      "239 64 278 120\n",
      "Processing  video_selected-008.png\n",
      "Face Detected:  2\n",
      "[366, 63, 26, 36]\n",
      "0.9999959468841553\n",
      "358 52 399 109\n",
      "[243, 74, 25, 35]\n",
      "0.9999622106552124\n",
      "235 63 275 119\n",
      "Processing  video_selected-009.png\n",
      "Face Detected:  2\n",
      "[365, 65, 24, 33]\n",
      "0.9999889135360718\n",
      "357 55 396 107\n",
      "[244, 73, 26, 36]\n",
      "0.9999675750732422\n",
      "236 62 277 119\n",
      "Processing  video_selected-010.png\n",
      "Face Detected:  2\n",
      "[366, 64, 25, 35]\n",
      "0.9999918937683105\n",
      "358 53 398 109\n",
      "[244, 71, 26, 36]\n",
      "0.9998053908348083\n",
      "236 60 277 117\n",
      "['.ipynb_checkpoints', '.vscode', 'app.py', 'app_ext.ipynb', 'app_ext.py', 'best_model_DFDC40_eff.h5', 'best_model_DFDC40_res.h5', 'Pipeline.py', 'static', 'templates', 'Untitled.ipynb']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-21 22:20:33,787] ERROR in app: Exception on /loading/prediction [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-7-eee0ab6885f3>\", line 25, in prediction\n",
      "    predictions=execute()\n",
      "  File \"<ipython-input-6-4fa909501b70>\", line 13, in execute\n",
      "    prediction=predict(faces_path,faces)\n",
      "  File \"<ipython-input-5-da99953dc9f0>\", line 10, in predict\n",
      "    img = tf.keras.preprocessing.image.load_img(os.path.join(faces_path,face), target_size=(128, 128))\n",
      "  File \"D:\\Anaconda\\lib\\ntpath.py\", line 78, in join\n",
      "    path = os.fspath(path)\n",
      "TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "127.0.0.1 - - [21/Jun/2021 22:20:33] \"\u001b[35m\u001b[1mGET /loading/prediction HTTP/1.1\u001b[0m\" 500 -\n",
      "127.0.0.1 - - [21/Jun/2021 22:21:41] \"\u001b[37mGET /static/css/style.css HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [21/Jun/2021 22:21:55] \"\u001b[33mGET /result.html HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [21/Jun/2021 22:21:55] \"\u001b[37mGET /loading HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [21/Jun/2021 22:21:55] \"\u001b[37mGET /static/css/style.css HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Fahad/Downloads\n",
      "video_selected.mp4\n",
      "video_selected.mp4\n",
      "Creating Directory: C:/Users/Fahad/Downloads\\video_selected\n",
      "Converting Video to Images...\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Done!\n",
      "Processing Directory: C:/Users/Fahad/Downloads\\video_selected\n",
      "Creating Directory: C:/Users/Fahad/Downloads\\video_selected\\faces\n",
      "Cropping Faces from Images...\n",
      "Processing  video_selected-000.png\n",
      "Face Detected:  0\n",
      "Processing  video_selected-001.png\n",
      "Face Detected:  2\n",
      "[241, 72, 27, 36]\n",
      "0.9993242025375366\n",
      "232 61 276 118\n",
      "[378, 56, 30, 43]\n",
      "0.7455229759216309\n",
      "Skipped a face..\n",
      "Processing  video_selected-002.png\n",
      "Face Detected:  2\n",
      "[402, 62, 23, 33]\n",
      "0.9999290704727173\n",
      "395 52 431 104\n",
      "[244, 73, 25, 34]\n",
      "0.9998849630355835\n",
      "236 62 276 117\n",
      "Processing  video_selected-003.png\n",
      "Face Detected:  2\n",
      "[378, 63, 24, 33]\n",
      "0.9999996423721313\n",
      "370 53 409 105\n",
      "[243, 70, 26, 38]\n",
      "0.999887228012085\n",
      "235 58 276 119\n",
      "Processing  video_selected-004.png\n",
      "Face Detected:  2\n",
      "[384, 62, 24, 34]\n",
      "0.9999954700469971\n",
      "376 51 415 106\n",
      "[251, 71, 23, 36]\n",
      "0.9999442100524902\n",
      "244 60 280 117\n",
      "Processing  video_selected-005.png\n",
      "Face Detected:  2\n",
      "[371, 60, 25, 36]\n",
      "0.999985933303833\n",
      "363 49 403 106\n",
      "[245, 71, 25, 35]\n",
      "0.9996850490570068\n",
      "237 60 277 116\n",
      "Processing  video_selected-006.png\n",
      "Face Detected:  2\n",
      "[368, 62, 26, 36]\n",
      "0.9999996423721313\n",
      "360 51 401 108\n",
      "[243, 71, 27, 36]\n",
      "0.9995806813240051\n",
      "234 60 278 117\n",
      "Processing  video_selected-007.png\n",
      "Face Detected:  2\n",
      "[365, 65, 24, 32]\n",
      "0.9999843835830688\n",
      "357 55 396 106\n",
      "[247, 75, 24, 35]\n",
      "0.999874472618103\n",
      "239 64 278 120\n",
      "Processing  video_selected-008.png\n",
      "Face Detected:  2\n",
      "[366, 63, 26, 36]\n",
      "0.9999959468841553\n",
      "358 52 399 109\n",
      "[243, 74, 25, 35]\n",
      "0.9999622106552124\n",
      "235 63 275 119\n",
      "Processing  video_selected-009.png\n",
      "Face Detected:  2\n",
      "[365, 65, 24, 33]\n",
      "0.9999889135360718\n",
      "357 55 396 107\n",
      "[244, 73, 26, 36]\n",
      "0.9999675750732422\n",
      "236 62 277 119\n",
      "Processing  video_selected-010.png\n",
      "Face Detected:  2\n",
      "[366, 64, 25, 35]\n",
      "0.9999918937683105\n",
      "358 53 398 109\n",
      "[244, 71, 26, 36]\n",
      "0.9998053908348083\n",
      "236 60 277 117\n",
      "['.ipynb_checkpoints', '.vscode', 'app.py', 'app_ext.ipynb', 'app_ext.py', 'best_model_DFDC40_eff.h5', 'best_model_DFDC40_res.h5', 'Pipeline.py', 'static', 'templates', 'Untitled.ipynb']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-21 22:22:14,876] ERROR in app: Exception on /loading/prediction [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-7-eee0ab6885f3>\", line 25, in prediction\n",
      "    predictions=execute()\n",
      "  File \"<ipython-input-6-4fa909501b70>\", line 13, in execute\n",
      "    prediction=predict(faces_path,faces)\n",
      "  File \"<ipython-input-5-da99953dc9f0>\", line 10, in predict\n",
      "    img = tf.keras.preprocessing.image.load_img(os.path.join(faces_path,face), target_size=(128, 128))\n",
      "  File \"D:\\Anaconda\\lib\\ntpath.py\", line 78, in join\n",
      "    path = os.fspath(path)\n",
      "TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "127.0.0.1 - - [21/Jun/2021 22:22:14] \"\u001b[35m\u001b[1mGET /loading/prediction HTTP/1.1\u001b[0m\" 500 -\n",
      "127.0.0.1 - - [21/Jun/2021 22:28:58] \"\u001b[37mGET /static/css/style.css HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [21/Jun/2021 22:29:06] \"\u001b[37mGET /loading HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [21/Jun/2021 22:29:06] \"\u001b[37mGET /static/css/style.css HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Fahad/Downloads\n",
      "video_selected.mp4\n",
      "video_selected.mp4\n",
      "Creating Directory: C:/Users/Fahad/Downloads\\video_selected\n",
      "Converting Video to Images...\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Original Dimensions:  (1080, 1920, 3)\n",
      "Scale Ratio:  0.33\n",
      "Resized Dimensions:  (356, 633, 3)\n",
      "Done!\n",
      "Processing Directory: C:/Users/Fahad/Downloads\\video_selected\n",
      "Creating Directory: C:/Users/Fahad/Downloads\\video_selected\\faces\n",
      "Cropping Faces from Images...\n",
      "Processing  video_selected-000.png\n",
      "Face Detected:  1\n",
      "[305, 58, 29, 36]\n",
      "0.9997197985649109\n",
      "296 47 342 104\n",
      "Processing  video_selected-001.png\n",
      "Face Detected:  1\n",
      "[303, 56, 28, 35]\n",
      "0.9955495595932007\n",
      "294 45 339 101\n",
      "Processing  video_selected-002.png\n",
      "Face Detected:  1\n",
      "[303, 56, 29, 36]\n",
      "0.9998142123222351\n",
      "294 45 340 102\n",
      "Processing  video_selected-003.png\n",
      "Face Detected:  1\n",
      "[305, 58, 28, 35]\n",
      "0.9995731711387634\n",
      "296 47 341 103\n",
      "Processing  video_selected-004.png\n",
      "Face Detected:  1\n",
      "[304, 58, 29, 38]\n",
      "0.9997953772544861\n",
      "295 46 341 107\n",
      "Processing  video_selected-005.png\n",
      "Face Detected:  1\n",
      "[302, 58, 27, 35]\n",
      "0.9984858632087708\n",
      "293 47 337 103\n",
      "Processing  video_selected-006.png\n",
      "Face Detected:  1\n",
      "[301, 60, 28, 35]\n",
      "0.9999955892562866\n",
      "292 49 337 105\n",
      "Processing  video_selected-007.png\n",
      "Face Detected:  1\n",
      "[302, 58, 28, 36]\n",
      "0.9994344115257263\n",
      "293 47 338 104\n",
      "Processing  video_selected-008.png\n",
      "Face Detected:  1\n",
      "[303, 61, 27, 35]\n",
      "0.9999890327453613\n",
      "294 50 338 106\n",
      "Processing  video_selected-009.png\n",
      "Face Detected:  1\n",
      "[304, 58, 27, 36]\n",
      "0.9995934367179871\n",
      "295 47 339 104\n",
      "Processing  video_selected-010.png\n",
      "Face Detected:  1\n",
      "[304, 59, 27, 35]\n",
      "0.999743640422821\n",
      "295 48 339 104\n",
      "['.ipynb_checkpoints', '.vscode', 'app.py', 'app_ext.ipynb', 'app_ext.py', 'best_model_DFDC40_eff.h5', 'best_model_DFDC40_res.h5', 'Pipeline.py', 'static', 'templates', 'Untitled.ipynb']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-21 22:29:26,093] ERROR in app: Exception on /loading/prediction [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-7-eee0ab6885f3>\", line 25, in prediction\n",
      "    predictions=execute()\n",
      "  File \"<ipython-input-6-4fa909501b70>\", line 13, in execute\n",
      "    prediction=predict(faces_path,faces)\n",
      "  File \"<ipython-input-5-da99953dc9f0>\", line 10, in predict\n",
      "    img = tf.keras.preprocessing.image.load_img(os.path.join(faces_path,face), target_size=(128, 128))\n",
      "  File \"D:\\Anaconda\\lib\\ntpath.py\", line 78, in join\n",
      "    path = os.fspath(path)\n",
      "TypeError: expected str, bytes or os.PathLike object, not NoneType\n",
      "127.0.0.1 - - [21/Jun/2021 22:29:26] \"\u001b[35m\u001b[1mGET /loading/prediction HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#from flaskthreads import AppContextThread\n",
    "@app.route('/')\n",
    "def index():\n",
    "    img='static/file.svg'\n",
    "    return render_template('index.html',img=img)\n",
    "\n",
    "@app.route('/loading')\n",
    "def loading():\n",
    "    return render_template('loading.html')\n",
    "\n",
    "@app.route('/team')\n",
    "def team():\n",
    "    return render_template('team.html')  \n",
    "\n",
    "@app.route('/about')\n",
    "def about():\n",
    "    return render_template('about.html')\n",
    "\n",
    "@app.route('/loading/prediction',methods=['GET','POST'])\n",
    "def prediction():\n",
    "     if request.method=='GET':\n",
    "        predictions=np.empty(1)\n",
    "        time.sleep(2)\n",
    "        predictions=execute()\n",
    "        value=predictions[0][0]*100#$[0][0])\n",
    "        value=round(value,2)\n",
    "        if(value < 1):\n",
    "            value = 3.00\n",
    "        return render_template('result.html',value=value)\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array([[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
